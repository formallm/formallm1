#!/usr/bin/env python3
"""
æ’è¡Œæ¦œæ•°æ®è·å–è„šæœ¬
ä» ForMaLLM ç«èµ› API è·å–æ’è¡Œæ¦œæ•°æ®å¹¶ä¿å­˜ä¸º JSON
"""

import requests
import json
import os
import sys
from datetime import datetime, timezone, timedelta

# API é…ç½®
API_BASE_URL = os.getenv("FORMALLM_API_BASE", "http://121.43.230.124")
API_KEY = os.getenv("FORMALLM_API_KEY", "default_api_key")  # è¯·æ›¿æ¢ä¸ºæ‚¨çš„çœŸå® API Key

# æ¯”èµ›é˜¶æ®µï¼ˆpreliminary æˆ– practiceï¼‰
STAGE = os.getenv("FORMALLM_STAGE", "preliminary")

# è¾“å‡ºæ–‡ä»¶è·¯å¾„ï¼ˆç›¸å¯¹äºä»“åº“æ ¹ç›®å½•ï¼‰
OUTPUT_FILE = "assets/data/leaderboard.json"


def fetch_daily_ranking(stage=STAGE, date=None):
    """
    è·å–æ¯æ—¥æ’è¡Œæ¦œ
    
    Args:
        stage: æ¯”èµ›é˜¶æ®µ
        date: æ—¥æœŸ (YYYY-MM-DD æ ¼å¼)ï¼Œé»˜è®¤ä¸ºä»Šå¤©
    
    Returns:
        dict: API å“åº”æ•°æ®
    """
    if date is None:
        # ä½¿ç”¨åŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰
        tz_beijing = timezone(timedelta(hours=8))
        date = datetime.now(tz_beijing).strftime('%Y-%m-%d')
    
    url = f"{API_BASE_URL}/ranking_list/daily"
    headers = {"X-API-Key": API_KEY}
    params = {"stage": stage, "dt": date}
    
    print(f"ğŸ“¡ è·å–æ¯æ—¥æ’è¡Œæ¦œ (æ—¥æœŸ: {date}, é˜¶æ®µ: {stage})...")
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        if "error" in data:
            print(f"âŒ API è¿”å›é”™è¯¯: {data['error']}")
            return None
        
        print(f"âœ… æˆåŠŸè·å–æ¯æ—¥æ’è¡Œæ¦œ")
        return data
    
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None


def _get_first_date_key(daily_payload: dict):
    """è¿”å›æ¯æ—¥æ•°æ®ä¸­çš„ç¬¬ä¸€ä¸ªæ—¥æœŸ keyï¼ˆå¿½ç•¥ stage å­—æ®µï¼‰ã€‚"""
    if not isinstance(daily_payload, dict):
        return None
    for key in daily_payload.keys():
        if key != "stage":
            return key
    return None


def _is_daily_payload_empty(daily_payload: dict) -> bool:
    """åˆ¤æ–­æ¯æ—¥æ¦œæ•°æ®æ˜¯å¦ä¸ºç©ºï¼ˆä¸¤ä¸ªèµ›é“éƒ½ä¸ºç©ºè§†ä¸ºæ— æ•°æ®ï¼‰ã€‚"""
    date_key = _get_first_date_key(daily_payload)
    if not date_key:
        return True
    day_data = daily_payload.get(date_key, {})
    return not (day_data.get("lean_ranking") or day_data.get("litex_ranking"))


def fetch_latest_daily_ranking(stage: str, preferred_date: str | None = None, lookback_days: int = 7):
    """
    è·å–æœ€è¿‘æœ‰æ•°æ®çš„ä¸€å¤©çš„æ¯æ—¥æ’è¡Œæ¦œã€‚

    ä¼˜å…ˆä½¿ç”¨ preferred_dateï¼›è‹¥æ— æˆ–è¯¥æ—¥æ— æ•°æ®ï¼Œåˆ™ä»â€œä»Šå¤©â€å¼€å§‹å¾€å›æœ€å¤š lookback_days å¤©ï¼Œ
    æ‰¾åˆ°ç¬¬ä¸€å¤©æœ‰æ•°æ®çš„æ—¥æœŸå¹¶è¿”å›å…¶ payloadã€‚
    """
    # 1) å¦‚æœæŒ‡å®šäº†æ—¥æœŸï¼Œä¼˜å…ˆå°è¯•
    if preferred_date:
        data = fetch_daily_ranking(stage, preferred_date)
        if data and not _is_daily_payload_empty(data):
            print(f"  ğŸ“… ä½¿ç”¨æŒ‡å®šæ—¥æœŸ: {preferred_date}")
            return data
        print(f"  âš ï¸ æŒ‡å®šæ—¥æœŸ {preferred_date} æ— æ•°æ®ï¼Œå›é€€åˆ°æœ€è¿‘æ—¥æœŸâ€¦")

    # 2) å›é€€æŸ¥æ‰¾æœ€è¿‘æœ‰æ•°æ®çš„æ—¥æœŸ
    tz_beijing = timezone(timedelta(hours=8))
    for delta in range(0, max(0, lookback_days) + 1):
        candidate = (datetime.now(tz_beijing) - timedelta(days=delta)).strftime('%Y-%m-%d')
        data = fetch_daily_ranking(stage, candidate)
        if data and not _is_daily_payload_empty(data):
            print(f"  ğŸ“… ä½¿ç”¨æ—¥æœŸ: {candidate}")
            return data

    # 3) å®åœ¨æ²¡æœ‰ï¼Œè¿”å›æœ€åä¸€æ¬¡å°è¯•çš„æ•°æ®ï¼ˆå¯èƒ½ä¸º None æˆ–ç©ºï¼‰
    return data


def fetch_overall_ranking(stage=STAGE, date=None):
    """
    è·å–æ€»æ’è¡Œæ¦œ
    
    Args:
        stage: æ¯”èµ›é˜¶æ®µ
        date: æ—¥æœŸ (YYYY-MM-DD æ ¼å¼)ï¼Œå¦‚æœæŒ‡å®šåˆ™è·å–æˆªæ­¢åˆ°è¯¥æ—¥æœŸçš„ç´¯è®¡æ’å
    
    Returns:
        dict: API å“åº”æ•°æ®
    """
    url = f"{API_BASE_URL}/ranking_list/overall"
    headers = {"X-API-Key": API_KEY}
    params = {"stage": stage}
    
    # å¦‚æœæŒ‡å®šäº†æ—¥æœŸï¼Œå°è¯•æ·»åŠ åˆ°å‚æ•°ä¸­ï¼ˆAPI å¯èƒ½æ”¯æŒ dt å‚æ•°ï¼‰
    if date:
        params["dt"] = date
        print(f"ğŸ“¡ è·å–æ€»æ’è¡Œæ¦œ (é˜¶æ®µ: {stage}, æˆªæ­¢æ—¥æœŸ: {date})...")
    else:
        print(f"ğŸ“¡ è·å–æ€»æ’è¡Œæ¦œ (é˜¶æ®µ: {stage})...")
    
    try:
        response = requests.get(url, headers=headers, params=params, timeout=30)
        response.raise_for_status()
        data = response.json()
        
        if "error" in data:
            print(f"âŒ API è¿”å›é”™è¯¯: {data['error']}")
            return None
        
        print(f"âœ… æˆåŠŸè·å–æ€»æ’è¡Œæ¦œ")
        return data
    
    except requests.exceptions.RequestException as e:
        print(f"âŒ è¯·æ±‚å¤±è´¥: {e}")
        return None


def transform_ranking_data(api_data):
    """
    å°† API è¿”å›çš„æ•°æ®è½¬æ¢ä¸ºå‰ç«¯éœ€è¦çš„æ ¼å¼
    
    Args:
        api_data: API è¿”å›çš„åŸå§‹æ•°æ®
    
    Returns:
        list: è½¬æ¢åçš„æ’è¡Œæ¦œæ¡ç›®
    """
    if not api_data:
        return []
    
    entries = []
    for item in api_data:
        entry = {
            "rank": item.get("ranking", 0),
            "teamName": item.get("team_name", "Unknown"),
            "teamId": item.get("team_id", ""),
            "score": float(item.get("score", 0)),
            "members": "",  # API ä¸­æ²¡æœ‰æˆå‘˜ä¿¡æ¯ï¼Œå¯ä»¥ä»å…¶ä»–æ¥æºè·å–
            "submitTime": "",  # æ ¹æ®éœ€è¦æ·»åŠ 
            "submissionCount": 0  # æ ¹æ®éœ€è¦æ·»åŠ 
        }
        entries.append(entry)
    
    return entries


def merge_leaderboard_data(daily_data, overall_data):
    """
    åˆå¹¶æ¯æ—¥å’Œæ€»æ¦œæ•°æ®ï¼Œç”Ÿæˆå‰ç«¯æ‰€éœ€çš„å®Œæ•´æ•°æ®ç»“æ„
    
    Args:
        daily_data: æ¯æ—¥æ’è¡Œæ¦œçš„ API å“åº”
        overall_data: æ€»æ’è¡Œæ¦œçš„ API å“åº”
    
    Returns:
        dict: å‰ç«¯éœ€è¦çš„å®Œæ•´æ•°æ®ç»“æ„
    """
    # ä» daily_data ä¸­æå–ç¬¬ä¸€ä¸ªæ—¥æœŸçš„æ•°æ®
    date_key = None
    lean_daily = []
    litex_daily = []
    
    if daily_data and isinstance(daily_data, dict):
        # è·å–ç¬¬ä¸€ä¸ªæ—¥æœŸ
        for key in daily_data.keys():
            if key != "stage":
                date_key = key
                break
        
        if date_key:
            day_data = daily_data[date_key]
            lean_daily = transform_ranking_data(day_data.get("lean_ranking", []))
            litex_daily = transform_ranking_data(day_data.get("litex_ranking", []))
    
    # ä» overall_data ä¸­æå–æ€»æ¦œæ•°æ®
    lean_overall = []
    litex_overall = []
    
    if overall_data and isinstance(overall_data, dict):
        lean_overall = transform_ranking_data(overall_data.get("lean_ranking", []))
        litex_overall = transform_ranking_data(overall_data.get("litex_ranking", []))
    
    # æ„å»ºæœ€ç»ˆæ•°æ®ç»“æ„
    tz_beijing = timezone(timedelta(hours=8))
    now = datetime.now(tz_beijing)
    
    result = {
        "lastUpdated": now.isoformat(),
        "stage": daily_data.get("stage", "preliminary") if daily_data else "preliminary",
        "litex": {
            "daily": litex_daily,
            "overall": litex_overall
        },
        "lean": {
            "daily": lean_daily,
            "overall": lean_overall
        }
    }
    
    return result


def save_json(data, filepath):
    """
    ä¿å­˜ JSON æ•°æ®åˆ°æ–‡ä»¶
    
    Args:
        data: è¦ä¿å­˜çš„æ•°æ®
        filepath: æ–‡ä»¶è·¯å¾„
    """
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(os.path.dirname(filepath), exist_ok=True)
    
    # ä¿å­˜ JSONï¼ˆæ ¼å¼åŒ–è¾“å‡ºï¼Œä¾¿äºæŸ¥çœ‹å’Œ Git diffï¼‰
    with open(filepath, 'w', encoding='utf-8') as f:
        json.dump(data, f, ensure_ascii=False, indent=2)
    
    print(f"ğŸ’¾ æ•°æ®å·²ä¿å­˜åˆ°: {filepath}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ† ForMaLLM ç«èµ›æ’è¡Œæ¦œæ•°æ®è·å–")
    print("=" * 60)
    print()
    
    # è·å–å‘½ä»¤è¡Œå‚æ•°ï¼ˆå¯é€‰çš„ API Keyã€Stageã€Daily Dateï¼‰
    if len(sys.argv) > 1:
        global API_KEY
        API_KEY = sys.argv[1]
        print(f"ğŸ”‘ ä½¿ç”¨è‡ªå®šä¹‰ API Key")
    
    if len(sys.argv) > 2:
        _ignored_stage = sys.argv[2]
        print(f"ğŸ“‹ å¿½ç•¥ä¼ å…¥é˜¶æ®µå‚æ•°ï¼Œå›ºå®šï¼šæ¯æ—¥=preliminaryï¼Œæ€»æ¦œ=preliminary")
    
    daily_date_override = sys.argv[3] if len(sys.argv) > 3 else None
    
    print()
    
    # 1. è·å–æ¯æ—¥æ’è¡Œæ¦œï¼ˆæ¯æ—¥æ¦œå›ºå®šä½¿ç”¨ preliminaryï¼›æ‰¾æœ€è¿‘æœ‰æ•°æ®çš„æ—¥æœŸï¼‰
    daily_stage = "preliminary"
    # ä½¿ç”¨åŒ—äº¬æ—¶åŒºçš„å½“å‰æ—¥æœŸï¼ˆå¦‚æœéœ€è¦å›ºå®šæ—¥æœŸï¼Œå¯ä»¥ä¼ å…¥ daily_date_overrideï¼‰
    tz_beijing = timezone(timedelta(hours=8))
    today = datetime.now(tz_beijing).strftime('%Y-%m-%d')
    preferred_date = daily_date_override if daily_date_override else today
    daily_data = fetch_latest_daily_ranking(daily_stage, preferred_date=preferred_date, lookback_days=7)
    
    # 2. è·å–æ€»æ’è¡Œæ¦œï¼ˆæ€»æ¦œå›ºå®šä½¿ç”¨ preliminaryï¼Œä¸æŒ‡å®šæ—¥æœŸè·å–æœ€æ–°æ•°æ®ï¼‰
    overall_stage = "preliminary"
    overall_data = fetch_overall_ranking(overall_stage, date=None)
    
    # 3. æ£€æŸ¥æ˜¯å¦è‡³å°‘æœ‰ä¸€ä¸ªæˆåŠŸ
    if not daily_data and not overall_data:
        print()
        print("âŒ æ— æ³•è·å–ä»»ä½•æ’è¡Œæ¦œæ•°æ®ï¼Œé€€å‡º")
        sys.exit(1)
    
    # 4. åˆå¹¶æ•°æ®
    print()
    print("ğŸ”„ åˆå¹¶æ•°æ®...")
    merged_data = merge_leaderboard_data(daily_data, overall_data)
    
    # 5. ä¿å­˜åˆ°æ–‡ä»¶
    print()
    save_json(merged_data, OUTPUT_FILE)
    
    # 6. æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
    print()
    print("=" * 60)
    print("ğŸ“Š æ•°æ®ç»Ÿè®¡:")
    print(f"  Litex æ¯æ—¥: {len(merged_data['litex']['daily'])} é˜Ÿ")
    print(f"  Litex æ€»æ¦œ: {len(merged_data['litex']['overall'])} é˜Ÿ")
    print(f"  Lean æ¯æ—¥: {len(merged_data['lean']['daily'])} é˜Ÿ")
    print(f"  Lean æ€»æ¦œ: {len(merged_data['lean']['overall'])} é˜Ÿ")
    print(f"  æ¯”èµ›é˜¶æ®µ: {merged_data['stage']}")
    print(f"  æ›´æ–°æ—¶é—´: {merged_data['lastUpdated']}")
    print("=" * 60)
    print()
    print("âœ… å®Œæˆï¼")


if __name__ == "__main__":
    main()

