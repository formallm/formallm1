#!/usr/bin/env python3
"""
æ¯æ—¥èµ›é¢˜æ–‡ä»¶ä¸‹è½½è„šæœ¬
ä» FormaLLM ç«èµ› API è·å–æ¯æ—¥èµ›é¢˜å¹¶ä¿å­˜åˆ°æ–‡ä»¶
"""

import requests
import json
import os
import sys
from datetime import datetime, timezone, timedelta
import pytz

# API é…ç½®
API_BASE_URL = os.getenv("FORMALLM_API_BASE", "http://121.43.230.124")
API_KEY = os.getenv("FORMALLM_API_KEY", "default_api_key")

# æ–‡ä»¶ä¿å­˜ç›®å½•
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
FILES_DIR = os.path.join(PROJECT_ROOT, "assets", "files")


def fetch_daily_problems(date=None, track="all"):
    """
    è·å–æ¯æ—¥èµ›é¢˜
    ä¼˜å…ˆä»æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè¯»å–ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™ä»è¿œç¨‹ API è·å–
    
    Args:
        date: æ—¥æœŸ (YYYY-MM-DD æ ¼å¼)ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        track: èµ›é“ ("lean", "litex", æˆ– "all")
    
    Returns:
        dict: {
            "date": "2025-11-06",
            "lean": [...],
            "litex": [...],
            "lean_file": "/path/to/lean_1106.jsonl",  # å¦‚æœä»æœ¬åœ°æ–‡ä»¶è¯»å–
            "litex_file": "/path/to/litex_1106.jsonl"  # å¦‚æœä»æœ¬åœ°æ–‡ä»¶è¯»å–
        }
    """
    if date is None:
        # ä½¿ç”¨åŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰
        tz_beijing = timezone(timedelta(hours=8))
        now_bj = datetime.now(tz_beijing)
        # å¦‚æœå½“å‰æ—¶é—´åœ¨ 23:00 ä¹‹åï¼Œè·å–ç¬¬äºŒå¤©çš„èµ›é¢˜
        if now_bj.hour >= 23:
            date = (now_bj + timedelta(days=1)).strftime('%Y-%m-%d')
            print(f"ğŸ• å½“å‰æ—¶é—´ {now_bj.strftime('%H:%M:%S')}ï¼Œè·å–ç¬¬äºŒå¤©èµ›é¢˜: {date}")
        else:
            date = now_bj.strftime('%Y-%m-%d')
            print(f"ğŸ• å½“å‰æ—¶é—´ {now_bj.strftime('%H:%M:%S')}ï¼Œè·å–å½“å¤©èµ›é¢˜: {date}")
    
    result = {
        "date": date,
        "lean": [],
        "litex": []
    }
    
    # è®¡ç®—æ–‡ä»¶åæ ¼å¼ï¼šMMDD (ä¾‹å¦‚ï¼š1109 è¡¨ç¤º 11æœˆ09æ—¥)
    date_obj = datetime.strptime(date, '%Y-%m-%d')
    date_str = date_obj.strftime('%m%d')  # MMDD æ ¼å¼
    
    # ä¼˜å…ˆä»æœ¬åœ°æ–‡ä»¶ç³»ç»Ÿè¯»å–
    if track in ["all", "lean"]:
        lean_filename = f"lean_{date_str}.jsonl"
        lean_filepath = os.path.join(FILES_DIR, lean_filename)
        
        if os.path.exists(lean_filepath):
            print(f"ğŸ“‚ ä»æœ¬åœ°æ–‡ä»¶è¯»å– Lean èµ›é¢˜: {lean_filename}")
            result["lean_file"] = lean_filepath
            # è¯»å–æ–‡ä»¶å†…å®¹ä»¥éªŒè¯æ–‡ä»¶æœ‰æ•ˆæ€§
            try:
                with open(lean_filepath, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    if lines:
                        # å°è¯•è§£æç¬¬ä¸€è¡ŒéªŒè¯æ ¼å¼
                        json.loads(lines[0].strip())
                        print(f"âœ… æœ¬åœ° Lean èµ›é¢˜æ–‡ä»¶æœ‰æ•ˆ: {len(lines)} é¢˜")
                    else:
                        print(f"âš ï¸  æœ¬åœ° Lean èµ›é¢˜æ–‡ä»¶ä¸ºç©º")
            except Exception as e:
                print(f"âš ï¸  æœ¬åœ° Lean èµ›é¢˜æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}ï¼Œå°†å°è¯•ä» API è·å–")
                result.pop("lean_file", None)
        else:
            print(f"ğŸ“¡ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä» API è·å– Lean èµ›é¢˜ (æ—¥æœŸ: {date})...")
            url = f"{API_BASE_URL}/problems/daily"
            headers = {"X-API-Key": API_KEY}
            params = {"date": date, "track": "lean"}
            
            try:
                response = requests.get(url, headers=headers, params=params, timeout=30)
                response.raise_for_status()
                data = response.json()
                
                if "error" not in data and isinstance(data, list):
                    result["lean"] = data
                    print(f"âœ… æˆåŠŸä» API è·å– Lean èµ›é¢˜: {len(data)} é¢˜")
                else:
                    print(f"âš ï¸  Lean èµ›é¢˜æš‚æ— æ•°æ®")
            except requests.exceptions.RequestException as e:
                print(f"âŒ Lean èµ›é¢˜è·å–å¤±è´¥: {e}")
    
    if track in ["all", "litex"]:
        litex_filename = f"litex_{date_str}.jsonl"
        litex_filepath = os.path.join(FILES_DIR, litex_filename)
        
        if os.path.exists(litex_filepath):
            print(f"ğŸ“‚ ä»æœ¬åœ°æ–‡ä»¶è¯»å– Litex èµ›é¢˜: {litex_filename}")
            result["litex_file"] = litex_filepath
            # è¯»å–æ–‡ä»¶å†…å®¹ä»¥éªŒè¯æ–‡ä»¶æœ‰æ•ˆæ€§
            try:
                with open(litex_filepath, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    if lines:
                        # å°è¯•è§£æç¬¬ä¸€è¡ŒéªŒè¯æ ¼å¼
                        json.loads(lines[0].strip())
                        print(f"âœ… æœ¬åœ° Litex èµ›é¢˜æ–‡ä»¶æœ‰æ•ˆ: {len(lines)} é¢˜")
                    else:
                        print(f"âš ï¸  æœ¬åœ° Litex èµ›é¢˜æ–‡ä»¶ä¸ºç©º")
            except Exception as e:
                print(f"âš ï¸  æœ¬åœ° Litex èµ›é¢˜æ–‡ä»¶æ ¼å¼é”™è¯¯: {e}ï¼Œå°†å°è¯•ä» API è·å–")
                result.pop("litex_file", None)
        else:
            print(f"ğŸ“¡ æœ¬åœ°æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°è¯•ä» API è·å– Litex èµ›é¢˜ (æ—¥æœŸ: {date})...")
            url = f"{API_BASE_URL}/problems/daily"
            headers = {"X-API-Key": API_KEY}
            params = {"date": date, "track": "litex"}
            
            try:
                response = requests.get(url, headers=headers, params=params, timeout=30)
                response.raise_for_status()
                data = response.json()
                
                if "error" not in data and isinstance(data, list):
                    result["litex"] = data
                    print(f"âœ… æˆåŠŸä» API è·å– Litex èµ›é¢˜: {len(data)} é¢˜")
                else:
                    print(f"âš ï¸  Litex èµ›é¢˜æš‚æ— æ•°æ®")
            except requests.exceptions.RequestException as e:
                print(f"âŒ Litex èµ›é¢˜è·å–å¤±è´¥: {e}")
    
    return result


def save_problems_to_files(problems_data):
    """
    å°†èµ›é¢˜æ•°æ®ä¿å­˜ä¸º JSONL æ–‡ä»¶ï¼ˆç›´æ¥å¤åˆ¶å·²æœ‰æ–‡ä»¶ï¼‰
    
    Args:
        problems_data: åŒ…å«æ—¥æœŸå’Œèµ›é¢˜çš„å­—å…¸ï¼Œæ”¯æŒä»é¢„ç½®æ–‡ä»¶å¤åˆ¶
    
    Returns:
        list: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    date = problems_data["date"]
    date_str = date.replace("-", "")  # 20251106
    saved_files = []
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(FILES_DIR, exist_ok=True)
    
    # ä¿å­˜ Lean èµ›é¢˜
    if problems_data.get("lean_file"):
        # å¦‚æœæä¾›äº†æºæ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥å¤åˆ¶ï¼ˆå¦‚æœæºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶ä¸åŒï¼‰
        source_file = problems_data["lean_file"]
        filename = f"lean_{date_str[4:]}.jsonl"  # lean_1106.jsonl
        filepath = os.path.join(FILES_DIR, filename)
        
        # æ ‡å‡†åŒ–è·¯å¾„ä»¥ä¾¿æ¯”è¾ƒ
        source_file_abs = os.path.abspath(source_file)
        filepath_abs = os.path.abspath(filepath)
        
        if source_file_abs != filepath_abs:
            import shutil
            shutil.copy2(source_file, filepath)
            print(f"ğŸ’¾ Lean èµ›é¢˜å·²å¤åˆ¶: {os.path.basename(source_file)} -> {filename}")
        else:
            print(f"ğŸ’¾ Lean èµ›é¢˜æ–‡ä»¶å·²åœ¨ç›®æ ‡ä½ç½®: {filename}")
        saved_files.append(filepath)
    elif problems_data["lean"]:
        # API æ–¹å¼ä¿å­˜
        filename = f"lean_{date_str[4:]}.jsonl"
        filepath = os.path.join(FILES_DIR, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            for problem in problems_data["lean"]:
                f.write(json.dumps(problem, ensure_ascii=False) + '\n')
        
        print(f"ğŸ’¾ Lean èµ›é¢˜å·²ä¿å­˜: {filename} ({len(problems_data['lean'])} é¢˜)")
        saved_files.append(filepath)
    
    # ä¿å­˜ Litex èµ›é¢˜
    if problems_data.get("litex_file"):
        # å¦‚æœæä¾›äº†æºæ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥å¤åˆ¶ï¼ˆå¦‚æœæºæ–‡ä»¶å’Œç›®æ ‡æ–‡ä»¶ä¸åŒï¼‰
        source_file = problems_data["litex_file"]
        filename = f"litex_{date_str[4:]}.jsonl"
        filepath = os.path.join(FILES_DIR, filename)
        
        # æ ‡å‡†åŒ–è·¯å¾„ä»¥ä¾¿æ¯”è¾ƒ
        source_file_abs = os.path.abspath(source_file)
        filepath_abs = os.path.abspath(filepath)
        
        if source_file_abs != filepath_abs:
            import shutil
            shutil.copy2(source_file, filepath)
            print(f"ğŸ’¾ Litex èµ›é¢˜å·²å¤åˆ¶: {os.path.basename(source_file)} -> {filename}")
        else:
            print(f"ğŸ’¾ Litex èµ›é¢˜æ–‡ä»¶å·²åœ¨ç›®æ ‡ä½ç½®: {filename}")
        saved_files.append(filepath)
    elif problems_data["litex"]:
        # API æ–¹å¼ä¿å­˜
        filename = f"litex_{date_str[4:]}.jsonl"
        filepath = os.path.join(FILES_DIR, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            for problem in problems_data["litex"]:
                f.write(json.dumps(problem, ensure_ascii=False) + '\n')
        
        print(f"ğŸ’¾ Litex èµ›é¢˜å·²ä¿å­˜: {filename} ({len(problems_data['litex'])} é¢˜)")
        saved_files.append(filepath)
    
    return saved_files


def update_downloads_json(problems_data, saved_files):
    """
    æ›´æ–° downloads.json é…ç½®æ–‡ä»¶
    
    Args:
        problems_data: èµ›é¢˜æ•°æ®
        saved_files: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    downloads_json_path = os.path.join(PROJECT_ROOT, "assets", "data", "downloads.json")
    
    if not os.path.exists(downloads_json_path):
        print("âš ï¸  downloads.json ä¸å­˜åœ¨ï¼Œè·³è¿‡æ›´æ–°")
        return
    
    # è¯»å–ç°æœ‰é…ç½®
    with open(downloads_json_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    # å‡†å¤‡æ–°çš„èµ›é¢˜æ¡ç›®
    # problems_data["date"] å·²ç»æ˜¯æ­£ç¡®çš„æ—¥æœŸï¼ˆ23:00åä¼šè‡ªåŠ¨æ˜¯ç¬¬äºŒå¤©çš„æ—¥æœŸï¼‰
    date = problems_data["date"]
    date_obj = datetime.strptime(date, '%Y-%m-%d')
    
    # è·å–å½“å‰åŒ—äº¬æ—¶é—´ç”¨äºæ—¶é—´æˆ³
    now_bj = datetime.now(pytz.timezone('Asia/Shanghai'))
    # ç›´æ¥ä½¿ç”¨ problems_data["date"] ä½œä¸ºæ˜¾ç¤ºæ—¥æœŸï¼ˆå·²ç»æ˜¯æ­£ç¡®çš„æ—¥æœŸï¼‰
    timestamp = f"{date_obj.strftime('%Y-%m-%d')} {now_bj.strftime('%H:%M:%S')}"
    title_date = date_obj
    
    print(f"ğŸ“… èµ›é¢˜æ—¥æœŸ: {date}")
    print(f"ğŸ• å½“å‰æ—¶é—´: {now_bj.strftime('%Y-%m-%d %H:%M:%S')}")
    print(f"ğŸ“ ç”Ÿæˆ timestamp: {timestamp}")
    print(f"ğŸ“‹ ç”Ÿæˆ title: {title_date.month}æœˆ{title_date.day}æ—¥èµ›é¢˜")
    
    items = []
    for filepath in saved_files:
        filename = os.path.basename(filepath)
        
        # è®¡ç®— MD5
        import hashlib
        md5_hash = hashlib.md5()
        with open(filepath, 'rb') as f:
            md5_hash.update(f.read())
        md5 = md5_hash.hexdigest()
        
        # ç¡®å®šèµ›é“åç§°ï¼ˆä½¿ç”¨ä¸ title ä¸€è‡´çš„æ—¥æœŸï¼‰
        if filename.startswith("lean"):
            name = f"Lean èµ›é¢˜ ({title_date.strftime('%mæœˆ%dæ—¥')})"
        elif filename.startswith("litex"):
            name = f"Litex èµ›é¢˜ ({title_date.strftime('%mæœˆ%dæ—¥')})"
        else:
            name = filename
        
        items.append({
            "name": name,
            "md5": md5,
            "url": "https://www.xir.cn/competitions/1143",
            "local": f"assets/files/{filename}",
            "available": True
        })
    
    # æ„å»ºæ–°çš„æ•°æ®é›†æ¡ç›®
    new_dataset = {
        "timestamp": timestamp,
        "title": f"{title_date.month}æœˆ{title_date.day}æ—¥èµ›é¢˜",
        "note": "æŠ¥ååå¯ä¸‹è½½æ•°æ®",
        "items": items
    }
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ—¥æœŸçš„èµ›é¢˜
    # ä½¿ç”¨ timestamp çš„æ—¥æœŸéƒ¨åˆ†æ¥åŒ¹é…ï¼ˆå› ä¸º23:00å timestamp å¯èƒ½æ˜¯æ˜å¤©çš„æ—¥æœŸï¼‰
    timestamp_date = timestamp[:10]  # æå– YYYY-MM-DD éƒ¨åˆ†
    existing_index = None
    for i, dataset in enumerate(config["datasets"]):
        dataset_timestamp = dataset.get("timestamp", "")
        dataset_date = dataset_timestamp[:10] if dataset_timestamp else ""
        if dataset_date == timestamp_date:
            existing_index = i
            break
    
    # æ›´æ–°æˆ–æ’å…¥æ–°æ¡ç›®
    if existing_index is not None:
        config["datasets"][existing_index] = new_dataset
        print(f"ğŸ”„ æ›´æ–°å·²å­˜åœ¨çš„èµ›é¢˜æ¡ç›®: {date}")
    else:
        config["datasets"].insert(0, new_dataset)
        print(f"â• æ·»åŠ æ–°çš„èµ›é¢˜æ¡ç›®: {date}")
    
    # æ›´æ–° lastUpdated
    tz_beijing = timezone(timedelta(hours=8))
    config["lastUpdated"] = datetime.now(tz_beijing).isoformat()
    
    # ä¿å­˜é…ç½®
    with open(downloads_json_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… downloads.json å·²æ›´æ–°")
    
    return config  # è¿”å›æ›´æ–°åçš„é…ç½®ï¼Œç”¨äºæ›´æ–° HTML


def convert_title_to_english(chinese_title):
    """
    å°†ä¸­æ–‡æ ‡é¢˜è½¬æ¢ä¸ºè‹±æ–‡æ ‡é¢˜
    ä¾‹å¦‚: "11æœˆ09æ—¥èµ›é¢˜" -> "Nov 9 Problems"
    """
    import re
    # åŒ¹é…æ ¼å¼ï¼šXXæœˆXXæ—¥èµ›é¢˜
    match = re.match(r'(\d+)æœˆ(\d+)æ—¥èµ›é¢˜', chinese_title)
    if match:
        month = int(match.group(1))
        day = int(match.group(2))
        month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 
                      'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
        if 1 <= month <= 12:
            return f"{month_names[month-1]} {day} Problems"
    # å¦‚æœæ— æ³•åŒ¹é…ï¼Œè¿”å›åŸæ ‡é¢˜
    return chinese_title


def update_html_embedded_json(config):
    """
    æ›´æ–° HTML æ–‡ä»¶ä¸­çš„å†…åµŒ JSON æ•°æ®
    
    Args:
        config: æ›´æ–°åçš„ downloads.json é…ç½®æ•°æ®
    """
    import re
    
    html_files = [
        (os.path.join(PROJECT_ROOT, "cn", "downloads.html"), "zh"),
        (os.path.join(PROJECT_ROOT, "en", "downloads.html"), "en")
    ]
    
    print(f"ğŸ“‚ é¡¹ç›®æ ¹ç›®å½•: {PROJECT_ROOT}")
    print(f"ğŸ“‚ HTML æ–‡ä»¶ç›®å½•: {os.path.join(PROJECT_ROOT, 'cn')} å’Œ {os.path.join(PROJECT_ROOT, 'en')}")
    print(f"ğŸ“‚ downloads.json è·¯å¾„: {os.path.join(PROJECT_ROOT, 'assets', 'data', 'downloads.json')}")
    print(f"ğŸ“‚ æ–‡ä»¶ä¿å­˜ç›®å½•: {os.path.join(PROJECT_ROOT, 'assets', 'files')}")
    
    for html_path, lang in html_files:
        print(f"\nğŸ” æ£€æŸ¥ HTML æ–‡ä»¶: {html_path}")
        if not os.path.exists(html_path):
            print(f"âš ï¸  HTML æ–‡ä»¶ä¸å­˜åœ¨: {html_path}")
            print(f"   å½“å‰å·¥ä½œç›®å½•: {os.getcwd()}")
            continue
        print(f"âœ… HTML æ–‡ä»¶å­˜åœ¨: {html_path}")
        
        try:
            # æ ¹æ®è¯­è¨€ç‰ˆæœ¬åˆ›å»ºé…ç½®å‰¯æœ¬å¹¶è½¬æ¢æ ‡é¢˜
            config_copy = json.loads(json.dumps(config))  # æ·±æ‹·è´
            
            # è°ƒæ•´è·¯å¾„ï¼šHTML æ–‡ä»¶åœ¨å­ç›®å½•ä¸­ï¼Œéœ€è¦æ·»åŠ  ../ å‰ç¼€
            # downloads.json ä¸­çš„è·¯å¾„æ˜¯ assets/files/...ï¼ˆç›¸å¯¹äºé¡¹ç›®æ ¹ï¼‰
            # HTML æ–‡ä»¶åœ¨ cn/ æˆ– en/ ç›®å½•ä¸­ï¼Œéœ€è¦ä½¿ç”¨ ../assets/files/...
            # éƒ¨ç½²è·¯å¾„ç¤ºä¾‹ï¼š
            #   HTML: /var/www/formallm1/cn/downloads.html
            #   downloads.json: /var/www/formallm1/assets/data/downloads.json
            #   æ–‡ä»¶: /var/www/formallm1/assets/files/...
            #   ä» cn/ è®¿é—® assets/files/ éœ€è¦ ../assets/files/
            path_adjusted_count = 0
            for dataset in config_copy.get("datasets", []):
                for item in dataset.get("items", []):
                    if "local" in item and item["local"]:
                        # å¦‚æœè·¯å¾„ä»¥ assets/ å¼€å¤´ä¸”æ²¡æœ‰ ../ å‰ç¼€ï¼Œåˆ™æ·»åŠ 
                        if item["local"].startswith("assets/") and not item["local"].startswith("../"):
                            old_path = item["local"]
                            item["local"] = "../" + item["local"]
                            path_adjusted_count += 1
                            if path_adjusted_count <= 2:  # åªæ‰“å°å‰2ä¸ªï¼Œé¿å…æ—¥å¿—è¿‡å¤š
                                print(f"   ğŸ”„ è·¯å¾„è°ƒæ•´: {old_path} -> {item['local']}")
            
            # åŒæ ·å¤„ç† examples ä¸­çš„è·¯å¾„
            for example in config_copy.get("examples", []):
                for item in example.get("items", []):
                    if "local" in item and item["local"]:
                        if item["local"].startswith("assets/") and not item["local"].startswith("../"):
                            old_path = item["local"]
                            item["local"] = "../" + item["local"]
                            path_adjusted_count += 1
            
            if path_adjusted_count > 0:
                print(f"   âœ… å·²è°ƒæ•´ {path_adjusted_count} ä¸ªæ–‡ä»¶è·¯å¾„ï¼ˆæ·»åŠ  ../ å‰ç¼€ï¼‰")
            
            # å¦‚æœæ˜¯è‹±æ–‡ç‰ˆæœ¬ï¼Œè½¬æ¢æ ‡é¢˜
            if lang == "en":
                for dataset in config_copy.get("datasets", []):
                    if "title" in dataset:
                        dataset["title"] = convert_title_to_english(dataset["title"])
                # è½¬æ¢ items ä¸­çš„ nameï¼ˆå¦‚æœæœ‰ä¸­æ–‡æ ¼å¼ï¼‰
                for dataset in config_copy.get("datasets", []):
                    for item in dataset.get("items", []):
                        if "name" in item:
                            # åŒ¹é…æ ¼å¼ï¼šLean èµ›é¢˜ (XXæœˆXXæ—¥) æˆ– Litex èµ›é¢˜ (XXæœˆXXæ—¥)
                            match = re.match(r'(Lean|Litex) èµ›é¢˜ \((\d+)æœˆ(\d+)æ—¥\)', item["name"])
                            if match:
                                track = match.group(1)
                                month = int(match.group(2))
                                day = int(match.group(3))
                                month_names = ['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 
                                              'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec']
                                if 1 <= month <= 12:
                                    item["name"] = f"{month_names[month-1]} {day} {track} Problems"
            
            # å‡†å¤‡ JSON å­—ç¬¦ä¸²ï¼ˆæ ¼å¼åŒ–ï¼Œ2 ç©ºæ ¼ç¼©è¿›ï¼‰
            json_str = json.dumps(config_copy, ensure_ascii=False, indent=2)
            
            # è¯»å– HTML æ–‡ä»¶
            with open(html_path, 'r', encoding='utf-8') as f:
                html_content = f.read()
            
            # ä½¿ç”¨æ›´å¯é çš„æ–¹æ³•ï¼šæ‰¾åˆ° script æ ‡ç­¾çš„å¼€å§‹å’Œç»“æŸä½ç½®
            # å…ˆæ‰¾åˆ° <script id="downloads-data"> çš„å¼€å§‹ä½ç½®
            script_start_pattern = r'<script\s+id=["\']downloads-data["\'][^>]*>'
            script_start_match = re.search(script_start_pattern, html_content)
            
            if not script_start_match:
                print(f"âš ï¸  HTML æ–‡ä»¶æœªæ‰¾åˆ° downloads-data script æ ‡ç­¾: {os.path.basename(html_path)}")
                continue
            
            print(f"ğŸ” æ‰¾åˆ° script æ ‡ç­¾: {os.path.basename(html_path)} ({lang})")
            script_start = script_start_match.end()  # script æ ‡ç­¾ç»“æŸä½ç½®ï¼ˆ> ä¹‹åï¼‰
            
            # ä» script æ ‡ç­¾åå¼€å§‹ï¼Œæ‰¾åˆ°å¯¹åº”çš„ </script> ç»“æŸä½ç½®
            # éœ€è¦æ‰¾åˆ°ä¸ <script> åŒ¹é…çš„ </script>ï¼Œè€Œä¸æ˜¯å…¶ä»– script æ ‡ç­¾çš„
            script_end_pattern = r'</script>'
            script_end_match = re.search(script_end_pattern, html_content[script_start:])
            
            if not script_end_match:
                print(f"âš ï¸  HTML æ–‡ä»¶æœªæ‰¾åˆ°å¯¹åº”çš„ </script> æ ‡ç­¾: {os.path.basename(html_path)}")
                continue
            
            print(f"ğŸ” æ‰¾åˆ° </script> æ ‡ç­¾: {os.path.basename(html_path)} ({lang})")
            
            script_end = script_start + script_end_match.start()  # </script> å¼€å§‹ä½ç½®
            
            # æå– JSON å†…å®¹ï¼ˆå»é™¤é¦–å°¾ç©ºç™½ï¼‰
            old_json_content = html_content[script_start:script_end].strip()
            
            # æ¯”è¾ƒ JSON å†…å®¹ï¼ˆè§£æåæ¯”è¾ƒï¼Œé¿å…æ ¼å¼å·®å¼‚ï¼‰
            try:
                old_json_data = json.loads(old_json_content)
                new_json_data = json.loads(json_str)
                # å¦‚æœ JSON å†…å®¹ç›¸åŒï¼Œåˆ™è·³è¿‡æ›´æ–°
                if old_json_data == new_json_data:
                    print(f"â„¹ï¸  HTML æ–‡ä»¶ JSON å†…å®¹æœªå˜åŒ–: {os.path.basename(html_path)} ({lang})")
                    continue
                else:
                    print(f"ğŸ”„ JSON å†…å®¹æœ‰å˜åŒ–ï¼Œå‡†å¤‡æ›´æ–°: {os.path.basename(html_path)} ({lang})")
            except json.JSONDecodeError as e:
                print(f"âš ï¸  è§£ææ—§ JSON å†…å®¹å¤±è´¥: {e}ï¼Œå°†å¼ºåˆ¶æ›´æ–°")
                # å¦‚æœè§£æå¤±è´¥ï¼Œç»§ç»­æ›´æ–°
            
            # è·å–ç¼©è¿›ä¿¡æ¯ï¼ˆä» script æ ‡ç­¾å‰çš„è¡Œè·å–ï¼‰
            script_tag_line_start = html_content.rfind('\n', 0, script_start_match.start()) + 1
            indent_str = html_content[script_tag_line_start:script_start_match.start()]
            # åªä¿ç•™ç©ºæ ¼/åˆ¶è¡¨ç¬¦
            indent_str = ''.join(c for c in indent_str if c in ' \t')
            
            # æ„å»ºæ–°çš„ HTML å†…å®¹
            new_html = (
                html_content[:script_start] + 
                '\n' + json_str + '\n' + indent_str + 
                html_content[script_end:]
            )
            
            # å†™å›æ–‡ä»¶
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(new_html)
            print(f"âœ… HTML å†…åµŒæ•°æ®å·²æ›´æ–°: {os.path.basename(html_path)} ({lang})")
            print(f"   ğŸ“ æ–‡ä»¶è·¯å¾„: {html_path}")
            print(f"   ğŸ“Š æ•°æ®é›†æ•°é‡: {len(config_copy.get('datasets', []))}")
            if config_copy.get('datasets'):
                latest = config_copy['datasets'][0]
                print(f"   ğŸ“… æœ€æ–°èµ›é¢˜æ—¥æœŸ: {latest.get('timestamp', 'N/A')[:10]}")
                print(f"   ğŸ“ æœ€æ–°èµ›é¢˜æ ‡é¢˜: {latest.get('title', 'N/A')}")
                
        except Exception as e:
            print(f"âŒ æ›´æ–° HTML æ–‡ä»¶å¤±è´¥ {os.path.basename(html_path)}: {e}")
            import traceback
            traceback.print_exc()


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ“ FormaLLM æ¯æ—¥èµ›é¢˜ä¸‹è½½")
    print("=" * 60)
    print()
    
    # è·å–å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        global API_KEY
        API_KEY = sys.argv[1]
        print(f"ğŸ”‘ ä½¿ç”¨è‡ªå®šä¹‰ API Key")
    
    date = sys.argv[2] if len(sys.argv) > 2 else None
    track = sys.argv[3] if len(sys.argv) > 3 else "all"
    
    print()
    
    # 1. è·å–èµ›é¢˜æ•°æ®
    problems_data = fetch_daily_problems(date, track)
    
    # æ£€æŸ¥æ˜¯å¦æœ‰èµ›é¢˜æ•°æ®ï¼ˆå¯èƒ½æ˜¯ä»æœ¬åœ°æ–‡ä»¶æˆ– API è·å–ï¼‰
    has_lean = problems_data.get("lean_file") or problems_data.get("lean")
    has_litex = problems_data.get("litex_file") or problems_data.get("litex")
    
    if not has_lean and not has_litex:
        print()
        print("âš ï¸  ä»Šæ—¥æš‚æ— èµ›é¢˜æ•°æ®")
        return
    
    # 2. ä¿å­˜ä¸º JSONL æ–‡ä»¶
    print()
    saved_files = save_problems_to_files(problems_data)
    
    if not saved_files:
        print("âš ï¸  æ²¡æœ‰ä¿å­˜ä»»ä½•æ–‡ä»¶")
        return
    
    # 3. æ›´æ–° downloads.json
    print()
    config = update_downloads_json(problems_data, saved_files)
    
    # 4. æ›´æ–° HTML æ–‡ä»¶ä¸­çš„å†…åµŒ JSON
    if config:
        print()
        print("=" * 60)
        print("ğŸ“„ å¼€å§‹æ›´æ–° HTML æ–‡ä»¶ä¸­çš„å†…åµŒ JSON...")
        print("=" * 60)
        update_html_embedded_json(config)
    else:
        print()
        print("âš ï¸  é…ç½®æ•°æ®ä¸ºç©ºï¼Œè·³è¿‡ HTML æ›´æ–°")
    
    print()
    print("=" * 60)
    print("âœ… èµ›é¢˜ä¸‹è½½å®Œæˆï¼")
    print(f"ğŸ“ ä¿å­˜æ–‡ä»¶æ•°: {len(saved_files)}")
    print("=" * 60)


if __name__ == "__main__":
    main()

