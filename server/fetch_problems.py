#!/usr/bin/env python3
"""
æ¯æ—¥èµ›é¢˜æ–‡ä»¶ä¸‹è½½è„šæœ¬
ä» FormaLLM ç«èµ› API è·å–æ¯æ—¥èµ›é¢˜å¹¶ä¿å­˜åˆ°æ–‡ä»¶
"""

import requests
import json
import os
import sys
from datetime import datetime, timezone, timedelta
import pytz

# API é…ç½®
API_BASE_URL = os.getenv("FORMALLM_API_BASE", "http://121.43.230.124")
API_KEY = os.getenv("FORMALLM_API_KEY", "default_api_key")

# æ–‡ä»¶ä¿å­˜ç›®å½•
SCRIPT_DIR = os.path.dirname(os.path.abspath(__file__))
PROJECT_ROOT = os.path.dirname(SCRIPT_DIR)
FILES_DIR = os.path.join(PROJECT_ROOT, "assets", "files")


def fetch_daily_problems(date=None, track="all"):
    """
    è·å–æ¯æ—¥èµ›é¢˜
    
    Args:
        date: æ—¥æœŸ (YYYY-MM-DD æ ¼å¼)ï¼Œé»˜è®¤ä¸ºä»Šå¤©
        track: èµ›é“ ("lean", "litex", æˆ– "all")
    
    Returns:
        dict: {
            "date": "2025-11-06",
            "lean": [...],
            "litex": [...]
        }
    """
    if date is None:
        # ä½¿ç”¨åŒ—äº¬æ—¶é—´ï¼ˆUTC+8ï¼‰
        tz_beijing = timezone(timedelta(hours=8))
        date = datetime.now(tz_beijing).strftime('%Y-%m-%d')
    
    # è¿™é‡Œéœ€è¦æ ¹æ®æ‚¨çš„å®é™… API ç«¯ç‚¹è°ƒæ•´
    # å‡è®¾ API æ ¼å¼ä¸º: /problems/daily?date=YYYY-MM-DD&track=lean
    
    result = {
        "date": date,
        "lean": [],
        "litex": []
    }
    
    if track in ["all", "lean"]:
        url = f"{API_BASE_URL}/problems/daily"
        headers = {"X-API-Key": API_KEY}
        params = {"date": date, "track": "lean"}
        
        print(f"ğŸ“¡ è·å– Lean èµ›é¢˜ (æ—¥æœŸ: {date})...")
        try:
            response = requests.get(url, headers=headers, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            if "error" not in data and isinstance(data, list):
                result["lean"] = data
                print(f"âœ… æˆåŠŸè·å– Lean èµ›é¢˜: {len(data)} é¢˜")
            else:
                print(f"âš ï¸  Lean èµ›é¢˜æš‚æ— æ•°æ®")
        except requests.exceptions.RequestException as e:
            print(f"âŒ Lean èµ›é¢˜è·å–å¤±è´¥: {e}")
    
    if track in ["all", "litex"]:
        url = f"{API_BASE_URL}/problems/daily"
        headers = {"X-API-Key": API_KEY}
        params = {"date": date, "track": "litex"}
        
        print(f"ğŸ“¡ è·å– Litex èµ›é¢˜ (æ—¥æœŸ: {date})...")
        try:
            response = requests.get(url, headers=headers, params=params, timeout=30)
            response.raise_for_status()
            data = response.json()
            
            if "error" not in data and isinstance(data, list):
                result["litex"] = data
                print(f"âœ… æˆåŠŸè·å– Litex èµ›é¢˜: {len(data)} é¢˜")
            else:
                print(f"âš ï¸  Litex èµ›é¢˜æš‚æ— æ•°æ®")
        except requests.exceptions.RequestException as e:
            print(f"âŒ Litex èµ›é¢˜è·å–å¤±è´¥: {e}")
    
    return result


def save_problems_to_files(problems_data):
    """
    å°†èµ›é¢˜æ•°æ®ä¿å­˜ä¸º JSONL æ–‡ä»¶ï¼ˆç›´æ¥å¤åˆ¶å·²æœ‰æ–‡ä»¶ï¼‰
    
    Args:
        problems_data: åŒ…å«æ—¥æœŸå’Œèµ›é¢˜çš„å­—å…¸ï¼Œæ”¯æŒä»é¢„ç½®æ–‡ä»¶å¤åˆ¶
    
    Returns:
        list: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    date = problems_data["date"]
    date_str = date.replace("-", "")  # 20251106
    saved_files = []
    
    # ç¡®ä¿ç›®å½•å­˜åœ¨
    os.makedirs(FILES_DIR, exist_ok=True)
    
    # ä¿å­˜ Lean èµ›é¢˜
    if problems_data.get("lean_file"):
        # å¦‚æœæä¾›äº†æºæ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥å¤åˆ¶
        source_file = problems_data["lean_file"]
        filename = f"lean_{date_str[4:]}.jsonl"  # lean_1106.jsonl
        filepath = os.path.join(FILES_DIR, filename)
        
        import shutil
        shutil.copy2(source_file, filepath)
        print(f"ğŸ’¾ Lean èµ›é¢˜å·²å¤åˆ¶: {source_file} -> {filename}")
        saved_files.append(filepath)
    elif problems_data["lean"]:
        # API æ–¹å¼ä¿å­˜
        filename = f"lean_{date_str[4:]}.jsonl"
        filepath = os.path.join(FILES_DIR, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            for problem in problems_data["lean"]:
                f.write(json.dumps(problem, ensure_ascii=False) + '\n')
        
        print(f"ğŸ’¾ Lean èµ›é¢˜å·²ä¿å­˜: {filename} ({len(problems_data['lean'])} é¢˜)")
        saved_files.append(filepath)
    
    # ä¿å­˜ Litex èµ›é¢˜
    if problems_data.get("litex_file"):
        # å¦‚æœæä¾›äº†æºæ–‡ä»¶è·¯å¾„ï¼Œç›´æ¥å¤åˆ¶
        source_file = problems_data["litex_file"]
        filename = f"litex_{date_str[4:]}.jsonl"
        filepath = os.path.join(FILES_DIR, filename)
        
        import shutil
        shutil.copy2(source_file, filepath)
        print(f"ğŸ’¾ Litex èµ›é¢˜å·²å¤åˆ¶: {source_file} -> {filename}")
        saved_files.append(filepath)
    elif problems_data["litex"]:
        # API æ–¹å¼ä¿å­˜
        filename = f"litex_{date_str[4:]}.jsonl"
        filepath = os.path.join(FILES_DIR, filename)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            for problem in problems_data["litex"]:
                f.write(json.dumps(problem, ensure_ascii=False) + '\n')
        
        print(f"ğŸ’¾ Litex èµ›é¢˜å·²ä¿å­˜: {filename} ({len(problems_data['litex'])} é¢˜)")
        saved_files.append(filepath)
    
    return saved_files


def update_downloads_json(problems_data, saved_files):
    """
    æ›´æ–° downloads.json é…ç½®æ–‡ä»¶
    
    Args:
        problems_data: èµ›é¢˜æ•°æ®
        saved_files: ä¿å­˜çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨
    """
    downloads_json_path = os.path.join(PROJECT_ROOT, "assets", "data", "downloads.json")
    
    if not os.path.exists(downloads_json_path):
        print("âš ï¸  downloads.json ä¸å­˜åœ¨ï¼Œè·³è¿‡æ›´æ–°")
        return
    
    # è¯»å–ç°æœ‰é…ç½®
    with open(downloads_json_path, 'r', encoding='utf-8') as f:
        config = json.load(f)
    
    # å‡†å¤‡æ–°çš„èµ›é¢˜æ¡ç›®
    date = problems_data["date"]
    date_obj = datetime.strptime(date, '%Y-%m-%d')
    
    # å¦‚æœå½“å‰æ—¶é—´åœ¨åŒ—äº¬æ—¶é—´23:00ä¹‹åï¼Œtimestamp å†™å…¥æ˜å¤©çš„æ—¥æœŸ
    # è¿™æ ·å‰ç«¯åœ¨23:00åå°±èƒ½åŒ¹é…åˆ°"æ˜å¤©"çš„èµ›é¢˜
    now_bj = datetime.now(pytz.timezone('Asia/Shanghai'))
    if now_bj.hour >= 23:
        # æ—¶é—´æˆ³ä½¿ç”¨æ˜å¤©çš„æ—¥æœŸ
        display_date = date_obj + timedelta(days=1)
        timestamp = display_date.strftime('%Y-%m-%d %H:%M:%S')
    else:
        timestamp = date_obj.strftime('%Y-%m-%d %H:%M:%S')
    
    items = []
    for filepath in saved_files:
        filename = os.path.basename(filepath)
        
        # è®¡ç®— MD5
        import hashlib
        md5_hash = hashlib.md5()
        with open(filepath, 'rb') as f:
            md5_hash.update(f.read())
        md5 = md5_hash.hexdigest()
        
        # ç¡®å®šèµ›é“åç§°
        if filename.startswith("lean"):
            name = f"Lean èµ›é¢˜ ({date_obj.strftime('%mæœˆ%dæ—¥')})"
        elif filename.startswith("litex"):
            name = f"Litex èµ›é¢˜ ({date_obj.strftime('%mæœˆ%dæ—¥')})"
        else:
            name = filename
        
        items.append({
            "name": name,
            "md5": md5,
            "url": "https://www.xir.cn/competitions/1143",
            "local": f"assets/files/{filename}",
            "available": True
        })
    
    # æ„å»ºæ–°çš„æ•°æ®é›†æ¡ç›®
    new_dataset = {
        "timestamp": timestamp,
        "title": f"{date_obj.month}æœˆ{date_obj.day}æ—¥èµ›é¢˜",
        "note": "æŠ¥ååå¯ä¸‹è½½æ•°æ®",
        "items": items
    }
    
    # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ç›¸åŒæ—¥æœŸçš„èµ›é¢˜
    existing_index = None
    for i, dataset in enumerate(config["datasets"]):
        if dataset.get("timestamp", "").startswith(date):
            existing_index = i
            break
    
    # æ›´æ–°æˆ–æ’å…¥æ–°æ¡ç›®
    if existing_index is not None:
        config["datasets"][existing_index] = new_dataset
        print(f"ğŸ”„ æ›´æ–°å·²å­˜åœ¨çš„èµ›é¢˜æ¡ç›®: {date}")
    else:
        config["datasets"].insert(0, new_dataset)
        print(f"â• æ·»åŠ æ–°çš„èµ›é¢˜æ¡ç›®: {date}")
    
    # æ›´æ–° lastUpdated
    tz_beijing = timezone(timedelta(hours=8))
    config["lastUpdated"] = datetime.now(tz_beijing).isoformat()
    
    # ä¿å­˜é…ç½®
    with open(downloads_json_path, 'w', encoding='utf-8') as f:
        json.dump(config, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… downloads.json å·²æ›´æ–°")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("ğŸ“ FormaLLM æ¯æ—¥èµ›é¢˜ä¸‹è½½")
    print("=" * 60)
    print()
    
    # è·å–å‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        global API_KEY
        API_KEY = sys.argv[1]
        print(f"ğŸ”‘ ä½¿ç”¨è‡ªå®šä¹‰ API Key")
    
    date = sys.argv[2] if len(sys.argv) > 2 else None
    track = sys.argv[3] if len(sys.argv) > 3 else "all"
    
    print()
    
    # 1. è·å–èµ›é¢˜æ•°æ®
    problems_data = fetch_daily_problems(date, track)
    
    if not problems_data["lean"] and not problems_data["litex"]:
        print()
        print("âš ï¸  ä»Šæ—¥æš‚æ— èµ›é¢˜æ•°æ®")
        return
    
    # 2. ä¿å­˜ä¸º JSONL æ–‡ä»¶
    print()
    saved_files = save_problems_to_files(problems_data)
    
    if not saved_files:
        print("âš ï¸  æ²¡æœ‰ä¿å­˜ä»»ä½•æ–‡ä»¶")
        return
    
    # 3. æ›´æ–° downloads.json
    print()
    update_downloads_json(problems_data, saved_files)
    
    print()
    print("=" * 60)
    print("âœ… èµ›é¢˜ä¸‹è½½å®Œæˆï¼")
    print(f"ğŸ“ ä¿å­˜æ–‡ä»¶æ•°: {len(saved_files)}")
    print("=" * 60)


if __name__ == "__main__":
    main()

